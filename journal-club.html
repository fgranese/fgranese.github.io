<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MARIANNE Journal Club 2025</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
</head>
<body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
        <div class="container">
            <a class="navbar-brand" href="#">MARIANNE Journal Club 2025</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link" href="#schedule">Schedule</a></li>
                    <li class="nav-item"><a class="nav-link" href="#award">Best Speaker Award</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <header class="p-4 text-center bg-success text-white">
        <h1>Journeys in Middle-Earth of LLMs</h1>
        <h4><i>MARIANNE Journal Club 2025</i></h4>
    </header>

    <section id="about" class="container my-5">
        <h2>About</h2>
        <p>Large Language Models (LLMs) have become a crucial part of AI research and applications. However, we often use them without deeply understanding their foundations. This journal club aims to explore LLMs from the ground up, covering seminal papers, key advancements, and their limitations.</p>

        <h6><u>Format</u></h6>
        <p>Each session lasts approximately 1 hour and 15 minutes, consisting of two presentations:</p>
        <ul>
            <li><strong>Long Paper Presentation:</strong> 30-minute presentation followed by a 15-minute Q&A session. The audience is encouraged to read the paper beforehand and actively participate in discussions.</li>
            <li><strong>Short Paper Presentation:</strong> A 15-minute presentation on a recent, relevant paper, followed by 10 minutes of discussion. The paper could be proposed by the speaker and it should be shared at least a week in advance.</li>
        </ul>
        <p>Speakers may choose their presentation style, whether using slides, the paper itself, a blackboard, or a combination.</p>
    </section>

    <section id="schedule" class="container my-5">
        <h2>Schedule</h2>
        <table class="table">
        <thead>
        <tr>
            <th>Date</th>
            <th>Long Paper Presentation (~30 min)</th>
            <th>Short Paper Presentation (~15 min)</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td style="background-color: #d4edda;"><strong>April 29, 2025 (14:00-15:15)</strong> Room: Euler Bleu</td>
            <td style="background-color: #d4edda;">Ekaterina: <a href="https://arxiv.org/pdf/2503.10622" target="_blank">Transformers without Normalization</a></td>
            <td style="background-color: #d4edda;">Cyprien: <a href="https://arxiv.org/abs/1706.03762" target="_blank">Attention Is All You Need</a></td>
        </tr>
        <tr>
            <td><strong>June 24, 2025 (14:00-15:15)</strong> Room: Salle du conseil</td>
            <td>Xiaoou: <a href="https://arxiv.org/abs/2005.14165" target="_blank">Language Models are Few-Shot Learners</a></td>
            <td>Greta/Deborah: <a href="https://arxiv.org/abs/2202.12837" target="_blank">Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?</a></td>
        </tr>
        <tr>
            <td><strong>September 29, 2025 (14:00-15:15)</strong> Room: Salle Galois Coriolis</td>
            <td>Greta: <a href="https://arxiv.org/pdf/2310.07064" target="_blank">Large Language Models Can Learn Rules</a></td>
            <td>Xiaoou/Ekaterina: <a href="https://arxiv.org/abs/2201.11903" target="_blank">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a></td>
        </tr>
        <tr>
            <td><strong>November 25, 2025 (14:00-15:15)</strong> Room: Salle Byron blanc</td>
            <td>Deborah: <a href="https://www.sciencedirect.com/science/article/pii/S0004370225000104" target="_blank">Argumentative review aggregation and dialogical explanations</a></td>
            <td>Cyprien: <a href="https://arxiv.org/pdf/2311.09022" target="_blank">Exploring the Potential of Large Language Models in Computational Argumentation</a></td>
        </tr>
        </tbody>
        </table>




<!--        <ul class="list-group">-->
<!--            <li class="list-group-item"><strong>April 29, 2025 (14:00-15:15):</strong> Ekaterina (Long) and Cyprien (Short)</li>-->
<!--            <li class="list-group-item"><strong>June 24, 2025 (14:00-15:15):</strong> Xiaoou (Long) and Greta/Deborah (Short)</li>-->
<!--            <li class="list-group-item"><strong>September 29, 2025 (14:00-15:15):</strong> Greta (Long) and Xiaoou/Ekaterina (Short) </li>-->
<!--            <li class="list-group-item"><strong>November 25, 2025 (14:00-15:15):</strong> Deborah (Long) and Cyprien (Short)</li>-->
<!--        </ul>-->
          <br>
<!--      <p><strong>Between March 21 and March 26 (AoE), each PhD candidate can indicate two available dates for their presentations (<a href="https://evento.renater.fr/survey/schedule-marianne-journal-club-2025-1qgn2mom">link</a>).-->
<!--          The final schedule will be published on March 29.</strong></p>-->

        <h6><u>Papers Proposals</u></h6>
<!--      <p>To get a better idea of what you might be most interested in, please indicate your preference at this <a href="https://evento.renater.fr/survey/papers-for-marianne-journal-club-2025-egskv8gd">link</a> by March 26 (AoE).</p>-->
        <ul>
            <li><strong>Transformers and BERT:</strong>
                            <i>For this session, I propose spending 15 minutes on Attention Is All You Need (which is probably already familiar) and dedicating 30 minutes to the new paper by LeCun, in order to compare the two papers.</i>

                <ul>
                    <li><a href="https://arxiv.org/abs/1706.03762" target="_blank"><strong>Attention Is All You Need</strong></a></li>
                    <li><a href="https://arxiv.org/abs/1810.04805" target="_blank">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></li>
                  <li><a href="https://arxiv.org/pdf/2503.10622" target="_blank"><strong>Transformers without Normalization</strong></a>. This work demonstrates that Transformers without normalization can achieve the same
or better performance using Dynamic Tanh operations.</li>
                </ul>
            </li>
          <li><strong>In-Context Learning (ICL):</strong> <i>For this session, the goal is to first understand what ICL is, and then explore how the models use it.</i>
                <ul>
                  <li><a href="https://arxiv.org/pdf/2301.00234" target="_blank">A Survey on In-context Learning</a> - Long presentation</li>
                    <li><a href="https://arxiv.org/abs/2005.14165" target="_blank">Language Models are Few-Shot Learners</a> (The seminal paper introducing the ICL terminology) - Long presentation</li>
                    <li><a href="https://arxiv.org/abs/2202.12837" target="_blank">Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?</a> - Short presentation</li>
                    <li><a href="https://arxiv.org/pdf/2303.03846" target="_blank">Larger Language Models do In-Context Learning Differently</a> - Short presentation</li>
                    <li><a href="https://arxiv.org/abs/2307.03172" target="_blank">Lost in the Middle: How Language Models Use Long Contexts</a> - Short presentation</li>
                </ul>
            </li>
          <li><strong>LLMs:</strong><i> For this session, depending on the selected papers, the focus could be on: (i) To Chain-of-Thought or not to Chain-of-Thought? (ii) What are Chain-of-Thought and Hypotheses-to-Theories?</i>
                <ul>
                  <li><a href="https://arxiv.org/abs/2201.11903" target="_blank"><strong>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</strong></a> (CoT does help) - Long presentation</li>
                    <li><a href="https://arxiv.org/abs/2001.08361" target="_blank">Scaling Laws for Neural Language Models</a> (OpenAI) - Long presentation</li>
                    <li><a href="https://arxiv.org/pdf/2310.07064" target="_blank"><strong>Large Language Models Can Learn Rules</strong></a> (Google DeepMind: Hypotheses-to-theories) Long/Short presentation</li>
                    <li><a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank">Improving Language Understanding by Generative Pre-Training</a> (GPT, OpenAI) - Long presentation</li>
                  <li><a href="https://arxiv.org/pdf/2405.04776" target="_blank"><strong>Chain of Thoughtlessness? An Analysis of CoT in Planning</strong></a> (CoT does not help) - Short presentation</li>
                </ul>
            </li>
          <li><strong>Argumentation/Explainability:</strong><i> For this session, the goal is to revisit the topic of argumentative AI and explore the applications of LLMs in this context.</i>
                <ul>
                   <li><a href="https://arxiv.org/pdf/1706.07269" target="_blank">Explanation in Artificial Intelligence: Insights from the Social Sciences</a> - Long presentation</li>
                    <li><a href="https://www.sciencedirect.com/science/article/pii/S0004370225000104" target="_blank">Argumentative review aggregation and dialogical explanations</a> - Long presentation</li>
                  <li><a href="https://arxiv.org/pdf/2311.09022"><strong>Exploring the Potential of Large Language Models in Computational Argumentation</strong></a> - Short presentation</li>
                  <li><a href="https://pubmed.ncbi.nlm.nih.gov/38045763/">Performance analysis of large language models in the domain of legal argument mining</a> - Short presentation</li>
                    <li><a href="https://arxiv.org/pdf/2412.08821">Large Concept Models: Language Modeling in a Sentence Representation Space</a> - Short presentation</li>
                </ul>
            </li>
            <li><strong>Some additional papers that could be of interest for short presentations:</strong>
                <ul>
                    <li><a href="https://arxiv.org/abs/2211.09527" target="_blank">Ignore Previous Prompt: Attack Techniques for Language Models</a> (Fooling LLMs)</li>
                    <li><a href="https://arxiv.org/pdf/2407.02551">Breach By A Thousand Leaks: Unsafe Information Leakage In Safe AI Responses</a> (Fooling LLMs)</li>
                </ul>
            </li>
        </ul>
    </section>

    <section id="award" class="container my-5">
        <h2>Best Speaker Award</h2>
        <p>The <strong>Best Speaker Award</strong> will be announced in December during the MARIANNE seminar. Stay tuned!</p>
    </section>

    <footer class="bg-dark text-white text-center py-3">
        <p>&copy; 2025 MARIANNE Journal Club. All rights reserved.</p>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>

<!--<!DOCTYPE html>-->
<!--<html lang="en">-->
<!--<head>-->
<!--    <meta charset="UTF-8">-->
<!--    <meta name="viewport" content="width=device-width, initial-scale=1.0">-->
<!--    <title>MARIANNE Journal Club 2025</title>-->
<!--    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">-->
<!--</head>-->
<!--<body>-->
<!--    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">-->
<!--        <div class="container">-->
<!--&lt;!&ndash;            <a class="navbar-brand" href="#">MARIANNE Journal Club 2025</a>&ndash;&gt;-->
<!--&lt;!&ndash;            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">&ndash;&gt;-->
<!--&lt;!&ndash;                <span class="navbar-toggler-icon"></span>&ndash;&gt;-->
<!--&lt;!&ndash;            </button>&ndash;&gt;-->
<!--            <div class="collapse navbar-collapse" id="navbarNav">-->
<!--                <ul class="navbar-nav">-->
<!--                    <li class="nav-item"><a class="nav-link" href="#about">About</a></li>-->
<!--                    <li class="nav-item"><a class="nav-link" href="#schedule">Schedule</a></li>-->
<!--                    <li class="nav-item"><a class="nav-link" href="#award">2025 Best Speaker Award</a></li>-->
<!--&lt;!&ndash;                    <li class="nav-item"><a class="nav-link" href="#participation">Get Involved</a></li>&ndash;&gt;-->
<!--                </ul>-->
<!--            </div>-->
<!--        </div>-->
<!--    </nav>-->

<!--    <header class="p-3 mb-2 bg-success text-white">-->
<!--        <h1>Journeys in Middle-Earth of LLMs</h1>-->
<!--      <h4><i>MARIANNE Journal Club 2025</i></h4>-->
<!--    </header>-->

<!--    <section id="about" class="container my-5">-->
<!--        <h2>About</h2>-->
<!--        <p>Large Language Models (LLMs) are (un)fortunately becoming essential to any AI practitioner's background. However, we are often more accustomed to using them than truly understanding them—a practice that can be detrimental in the long run. In this series of presentations, we will take a break from the daily "paper" grind to explore LLMs from the ground up. We will start with the seminal papers that laid the foundation for this technology, move through key advancements, and conclude by examining their limitations and how to exploit them.</p>-->
<!--        <h6><u>Organization</u></h6>-->
<!--        <p>Each session is 1h15 (+/-15 minutes) and two presentations. One presentation from Long papers and the second Short papers</p>-->

<!--        <ul>-->
<!--          <li>The first presentation can last 1 hour, considering 30 minutes of presentation and 15 minutes of QA.-->
<!--          The audience will be invited to read the paper before the presentation, and each one will be highly encouraged to ask one question. This is to simulate seminar presentations/jury questions.-->
<!--          </li>-->
<!--          <li>In the second presentation, the speaker will propose the paper to present (e.g., a cool paper from one of the latest conferences). The paper should be provided at least one week before the presentation to allow the audience to familiarise with it.-->
<!--The presentation can last 15 minutes + 10 minutes QA. This is to simulate oral presentations at conferences.-->
<!--</li>-->
<!--        </ul>-->
<!--      <p>The speaker can decide how to present the work, using slides, the paper, the blackboard, or a combination</p>-->
<!--    </section>-->

<!--    <section id="schedule" class="container my-5">-->
<!--        <h2>Schedule</h2>-->
<!--        <ul class="list-group">-->
<!--            <li class="list-group-item"><strong>April 29, 2025 (14h00-15h15):</strong> Transformers and BERT</li>-->
<!--            <li class="list-group-item"><strong>June 24, 2025 (14h00-15h15):</strong> In-Context Learning (ICL)</li>-->
<!--            <li class="list-group-item"><strong>September 29, 2025 (14h00-15h15):</strong> LLMs</li>-->
<!--            <li class="list-group-item"><strong>November 25, 2025 (14h00-15h15):</strong> Fooling LLMs</li>-->
<!--        </ul>-->
<!--      <p></p>-->
<!--      <p><strong>From 21 March to 26 March (AoE), each PhD student must indicate two days on which he/she can be available to make the presentation (Long and Short).-->
<!--        On the 29th of March, we will publish the finalized calendar.</strong></p>-->
<!--      <h6><u>Papers</u></h6>-->
<!--      Transformers and BERT:-->
<!--Attention is all you need-->
<!--Bert: Pre-training of Deep Bidirectional Transformer for Language Understanding-->
<!--In Context Learning (ICL):-->
<!--Language Models are Few-Shot Learners (42 pages)-->
<!--Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?-->
<!--Lost in the Middle: How Language Models Use Long Contexts-->
<!--LLMs:-->
<!--Scaling Laws for Neural Language Models (Open AI)-->
<!--Large Language Models can Learn Rules (Google DeepMind)-->
<!--Improving Language Understanding by Generative Pre-Training (GPT, OpenAI)-->
<!--Chain-of-Thought Prompting Elicits Reasoning in Large Language Models-->

<!--Fooling LLMs:-->
<!--Ignore Previous Prompt: Attack Techniques For Language Models-->

<!--I will check for some other papers on Text Summarization attacks-->
<!--    </section>-->

<!--    <section id="award" class="container my-5">-->
<!--        <h2>Best Speaker Award</h2>-->
<!--        <p>Stay Tuned! In December, during the MARIANNE seminar, the Best Speaker Award of the Year will be announced!</p>-->
<!--    </section>-->

<!--&lt;!&ndash;    <section id="participation" class="container my-5">&ndash;&gt;-->
<!--&lt;!&ndash;        <h2>Get Involved</h2>&ndash;&gt;-->
<!--&lt;!&ndash;        <p>We encourage active participation through questions, discussions, and votes for the Best Speaker Award. Join us and contribute to the exploration of LLMs!</p>&ndash;&gt;-->
<!--&lt;!&ndash;    </section>&ndash;&gt;-->

<!--&lt;!&ndash;    <footer class="bg-dark text-white text-center py-3">&ndash;&gt;-->
<!--&lt;!&ndash;        <p>&copy; 2025 Thematic Journal Club. All rights reserved.</p>&ndash;&gt;-->
<!--&lt;!&ndash;    </footer>&ndash;&gt;-->

<!--    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>-->
<!--</body>-->
<!--</html>-->